{"pages":[{"title":"","text":"a0bcc38ffcd04d4ad358df904d161a48","link":"/baidu_verify_code-012lfZzLKq.html"}],"posts":[{"title":"关于个人博客网站的说明","text":"提要我已经初步完成了个人博客的搭建，也申请了一个域名作为博客的主页。名字就叫“William Leung的个人博客”，地址为https://williamleung.cn/ 我在此写一篇博客来阐述我搭建个此个人博客的初衷以及未来的规划。 正文1.为什么要搭建这个博客呢？ 为了在学习的过程中记录一些心得与体会，方便以后的复习。如果将学习笔记记在笔记本中容易丢失，而且携带很不方便。若是将笔记记在iPad中虽然解决了携带的问题，但对于一些需要跑代码配环境的知识难以记录，而且iPad的iCloud云容量小，并不能满足我的学习需求。所以我决定搭建一个博客，提高学习以及复习的效率。 分享一些学到的知识，教会有学习需要的人。我自己学习的过程，记下的笔记对于想学习相同知识的人来说或许是一个宝贵的财富。我可以把我学习过程中遇到的一些坑标记出来，以防后人再跌入这个坑中。当自己学会东西时，我需要和他人分享来获得分享的喜悦。这也算是激励自己学习的一个方式吧。而且根据费曼学习法，教会别人其实也是一种很好的学习方式。 写博客可以提升自己的技术写作能力。对于很多理工科的学生来说，写文章简直就是噩梦。而写博客则可以锻炼自己的写作能力，博客写多了，熟能生巧，到最后能力总会有所提高。 可以让想了解我能力的人迅速了解我。对于不了解的人，想要再短时间内对技术能力进行考核是比较难的。而阅读一个人的技术博客可以快速了解这个人所掌握的知识以及技能，从而更快的判断出这个人是否符合自己所对其的预设以及期望。 2.为什么不用别人的博客系统 自己搭建的博客更加的个性化，可以满足自己的不同需求。 我个人认为在第三方的博客中：CSDN广告十分的多；新浪博客网易博客早已过时，无人问津；豆瓣、娱乐性质太高不适合写技术博客；简书、博客园的版面设计不符合我的审美。 我看到过很多大神都有了自己的博客，我十分的羡慕，也希望拥有一个自己的个人博客。 自己搭建一个个人博客也是一个学习的过程。在学习的过程中又可以达到自己想有一个博客的目的，一举两得。 3.博客上会发布什么内容？ 现在是初建博客的阶段，我暂时也没有想好会做一些什么方面的内容。由于我是学习人工智能方向的大学生，并且有考研的想法。初步将范围界定在一下范围中。 408（数据结构、计算机组成、操作系统、计算机网络） 考研数学（高等数学、概率论、线性代数） 人工智能相关方向（如Python、TensorFlow、神经网络、机器学习 等） 一些非专业的内容（比如某些电影、书籍的观后感，游记，随笔，以及非本专业的其他领域的内容等） 专业知识的学习与分享我将放在专门的类别当中，随笔将会放到杂项里。 2022.5.27更新：我发现我并没有太多精力写如此广阔范围的博客，故将博客范文限定在计算机方向内。目前只有论文精度一个板块。 总结虽然我的专业是计算机科学与技术，但我并没有选开发方向，对网页开发并不是很了解，在搭建过程中很多东西我不是很清楚，大多数都是现学现卖。但是在这个网站的开发过程中，我也学到了很多知识，了解了很多计算机学科的知识。总之离全栈工程师又进了一步。 在写这篇博客的时候我的博客已经基本搭建完成。但具体的搭建方法我还没有整理出来，等有时间后我会再写一篇博客，具体的写出我搭建本博客的方法以及过程，以供大家学习参考。","link":"/posts/1/"},{"title":"AlexNet论文精读","text":"概述AlexNet是2012年ImageNet竞赛冠军获得者Alex Krizhevsky、Hinton（获2019图灵奖）和Ilya Sutskever（Alpha GO、TensorFlow的开发者）设计的。原论文名为ImageNet Classification with Deep Convolutional Neural Networks（使用深度神经网络对ImageNet进行图像分类），是计算机视觉领域最为经典的论文之一，引用量至今已达1.4万次，主要提出者Alex Krizhevsky是人工智能教父Hinton的学生，这三位作者被称为人工智能三巨头。 因为AlexNet的提出，使得那一年之后，更多的更深的神经网络被提出，比如优秀的VGG,GoogLeNet，他们都是基于AlexNet的深度卷积神经网络来提取图像特征的。尽管AlexNet是2012年提出的模型，在如今已经有了更多的更优秀的模型，但是他们都是从AlexNet中得到启发。其首次将深度学习应用在大规模的图像分类上，在当时在产业界和学术界引发了很大的轰动。之后不管是图像分类，目标检测、语义分割都是在AlexNet的基础之上，AlexNet奠定了计算机视觉深度学习的基本模型方法和技巧。所以我认为AlexNet是学习计算机视觉必须了解的一个模型。 今天我将通过精读这篇论文原文的方式去了解AlexNet的一些基本思想和原理，下面我主要通过下面四个方面来对这篇论文进行精读。 AlexNet 网络结构及参数计算 AlexNet 网络特色及训练技巧 实验设置及结果分析 论文总结 AlexNet论文链接：http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf 文章目录 摘要 论文小标题 AlexNet 网络结构 ReLU Training on Multiple GPUs Local Response Normalization（局部响应标准化） Overlapping Pooling Reducing Overfitting 实验结果与分析 论文总结 下面，我们首先来看看摘要。 摘要 我们可以将摘要总结如下： 在 ILSVRC-2010 的120万图片上训练深度卷积神经网络，获得最优结果，top-1 和 top-5 error 分别为 37.5% 和 17%。 在 Alexnet 中，一共有6千万个参数和65万个神经元，包括5个卷积层和3个全连接层。 为了训练的更快，Alexnet 使用了非饱和激活函数——ReLU，采用GPU进行训练 为了防止过拟合，在全连接层采取了 “dropout” 的方法。 基于以上技巧，在 ILSVRC-2012 以超出第二名10.9个百分点成绩夺冠。 论文小标题 看完了摘要，我们应该将这篇论文的小标题列举出来，通过观察这些小标题，我们大致就可以看出这篇论文的大致框架是怎样的。 可以看出，我们应该重点关注第3部分，它的子标题也是最多的。我们可以看到 3.5 是一个总览框架，所以我们阅读时可以先看 3.5，再去看 3.1-3.4。 下面我们就从 AlexNet 网络结构出发（3.5）。 AlexNet 网络结构 我们先看 3.5 的总体框架。 可以从上面两段文字总结如下： 这个网络包括8个带权重的层，5个卷积层和3个全连接层。 第2，4，5层只和相同 GPU 上的前一层相连接。 第3层和第2层中所有 GPU 上的前一层相连。 在第1层和第2层后有 LRN 层。 最大池化层会在第1，2，5层之后。 ReLU函数会在所有的卷积层和全连接层。 接下来我们看看对图的描述。 在文字中，神经网络的输入是 150,528 维度的，从图中就可以看出，输入是 224x224x3 = 150528。然后每层的神经元个数如下： 我们按照之前的文字描述将原神经网络给描述得更清晰一些： 如果你还是不太明白，那么就看下面这张图： 但是你看到第一层，你就可能会有一个疑问，输入层不是 224x224 吗，怎么变成了 227x227，那是因为如果将 224x224 代入 F o F_oF**o 公式计算会出现不能整除的情况，所以为了避免这种情况，应该将此处的 padding 设为 2，代入F o F_oF**o 公式可得到输出后的大小为 55*55。 接下来，我们就来计算一下，这个网络怎么得到的 6000 万个参数。 我们通过上面的公式计算一下第一层的连接数量：3 * 11 * 11 * 96 + 96 = 34944，第二层的连接数为：96 * 5 * 5 * 256 + 256 = 614656，以此类推。但是我们观察到 FC1 层的连接数量为 37,752,832 个，占了整个连接数量的一半，所以全连接层是非常消耗内存的。 我们现在已经整体的把握了 AlexNet 的网络结构，我们再倒回去看 3.1-3.4 的部分，来看看该网络到底是怎么实现的。 根据上面一段话可知，3.1-3.4 是按照重要程度依次递减排列的。那么我们将 3.1-3.4 的小标题再列出来： 3.1 ReLU Nonlinearity（the most important） 3.2 Training on Multiple GPUs 3.3 Local Response Normalization（局部相应标准化） 3.4 Overlapping Pooling 3.1 ReLU下面，我们就来看看 3.1。 上面一段话表明，通常我们模型的激活函数会选择 tanh 或者 sigmoid 函数，但是它们都是属于饱和函数，在这个模型中，采用的是非饱和非线性的激活函数 —— ReLU 函数。因为就梯度下降的训练时间而言，饱和函数要比非饱和函数慢得多。可以从下图中观察得知： 从上图可以得知，当 Training error rate 下降到 0.25 时，ReLU 函数需要训练大概 6 个 epoch，而 tanh 要训练 36 个 epoch，两个函数差了 6 倍之多，可见该网络模型的成功离不开 ReLU 函数。 那么 ReLU 还有哪些优点呢？ 使网络训练更快 防止梯度消失 使网络具有稀疏性 下面就来看一下 ReLU 函数和 Sigmoid 函数曲线的对比： 补充：饱和函数 3.2 Training on Multiple GPUs 该模型主要使用了2个GPU，在模型总览那里我们已经了解了怎么使用多 GPU，这里就不再赘述了。 3.3 Local Response Normalization（局部响应标准化） 局部响应标准化：有助于 AlexNet 泛化能力的提升，受真实神经元侧抑制（lateral inhibition）启发。 侧抑制：细胞分化变为不同时，它会对周围细胞产生抑制信号，阻止它们向相同方向分化，最终表现为细胞命运的不同。 在论文中提到了一个公式，下面我们就来解释一下这个公式： b x , y i b_{x,y}^ib**x,y**i：表示神经元局部响应标准化后的值，i ii 表示通道，x , y x, yx,y 像素的位置 a x , y i a_{x,y}^ia**x,y**i：表示神经元局部响应标准化前的值 k kk：超参数，由原型中的 bias 指定 α αα：超参数，由原型中的 α αα N NN：每个特征图里面最内层向量的列数 β ββ：超参数，由原型中的 β ββ 指定 其中，k = 2 , n = 5 , α = 1 e − 4 , β = 0.75 k=2, n=5, α=1e-4, β=0.75k=2,n=5,α=1e−4,β=0.75 式子中的 max(0, i-n/2) 和 min(N-1, i+n/2) 是为了边界溢出的问题。我们真正需要关心的是 i-n/2 和 i+n/2。假设我们当前通道为 i ii，我们会往左考虑 n/2 个通道，向右考虑 n/2 个通道，这就对应了侧抑制概念中当细胞分化不同时，它会对周围细胞产生抑制信号。而左右 n/2 对应周围细胞。其实这个公式就是看分母，如果分母越大，那么最后得出的值相对就会比较小，就表现出抑制的作用。 3.4 Overlapping Pooling 我们先来看一下我们常见的池化方式是怎样的？ 上图中输入特征图是 44 的，它的滑动窗口大小是 22 的，那么它会进行4次池化，而且每次池化的部分是不重叠的（每一部分用不同颜色区分）。通常，我们就会将移动的步长 s 设置为滑动窗口大小，即 s = 2。但是该模型中使用的是有重叠的池化，即 s &lt; 滑动窗口大小。 以上就是神经网络大致结构。下面我们就来看看网络的训练技巧，这就是第 4 小节的内容了，Reducing Overfitting。 Reducing Overfitting 这篇论文主要使用的减少过拟合的技巧有两个：Data Augmentation 和 Dropout。 下面我们先来看看 4.1 Data Augmentation 主要使用了哪些方法。 (1)：在训练阶段，从大小为 256256 的图片中随机截取出 224224 的图片，然后再经过水平翻转，我们可以得到 2048 张图片。(2)：2048 = (256-224)^2 * 2 平方表示宽和高两方面，2 表示水平翻转(3)：在测试阶段采取的方法是从一张 256256 的图片截取 5 张 224*224 的图片，分别从左上角，右上角，左下角，右下角，中心截取5张，然后分别进行水平翻转获得10张图片。 可见第一种方法使用的是裁剪和翻转来使数据量扩增。下面我们来看看第二种方法。 主要说的就是对图像颜色的扰动。 下面我们总结一下针对 Data Augmentation 采取的两种方法： 说完了 Data Augmentation。再来看看 Dropout（随即失失活）。 实验结果与分析 我们主要分析三个部分： 下面先来看看第一部分，在 ILSVRC-2012 挑战赛中的成果。下表表示了 AlexNet 在 Top-1 和 Top-5 这两个指标上的变化情况，它采用了四种不同的方式来获取这些指标。我们要去学习网络不断改进的思路和方法。 接下来我们看 Qualitative Evaluations。 从上图的有右图可以得出特征的相似性：相似图片的第二个全连接层输出特征向量的欧氏距离相近。 启发：可用 AlexNet 提取高级特征进行图像检索、图像聚类、图像编码。 论文总结 在研究完每篇论文之后，我们都需要做一个总结。主要从三方面进行总结：关键点、创新点和启发点。 那么我们先来看一下这篇论文的总结是什么? 第一段其实主要想讲关于模型的网络结构之间的相关联是非常重要的，例如，我们移除了某一个神经网络的卷积层，这个模型的性能会下降大概2%。同样的，我们在使用网络的时候，也不要随意增加网络的层数。 第二段主要是想讲未来的研究方向，这也是大部分论文在论文结尾都会点出来的，自己的不足或者未来可以去发展的方向。这里它提到未来可以用视频的数据来训练一个更大的卷积神经网络。因为这里提到一些时序上的信息的缺失，AlexNet 都是基于 2D 的图片，是缺少时间这个维度的，而视频数据恰恰补充了这个信息，所以这里提出来了未来可以研究的方向就是基于视频信息来训练一个更大的卷积神经网络。 下面就来进行自我总结。 关键点 大量带标签的数据 —— ImageNet（算料） 高性能计算资源 —— GPU（算力） 合理算法模型 —— 深度卷积神经网络（算法） 创新点 采用 ReLU 加快大型神经网络训练 采用 LRN 提升大型网络泛化能力 采用 Overlapping Pooling 提升指标 采用随机裁剪翻转及色彩扰动增加数据多样性（重点） 采用 Dropout 减轻过拟合（FC层） 启发点 深度与宽度可决定网络能力Their capacity can be controlled by varying their depth and breadth. （1 Introduction p2） 更强大的GPU及更多数据可进一步提高模型性能All of our experiments suggest that our resultscan be improved simply by waiting for faster GPUs and bigger datasets to become available. 图片缩放细节，对短边先缩放Given arectangular image, we first rescaled the image such that the shorter side was of length 256, and thencropped out the central 256×256 patch from the resulting image.（2 Dataset p3） ReLU 不需要对输入进行标准化来防止饱和现象，即说明 sigmoid/tanh 激活函数有必要对输入进行标准化ReLUs have the desirable property that they do not require input normalization to prevent themfrom saturating. （3.3 LRN p1）","link":"/posts/12577bd1/"},{"title":"VGG论文精读","text":"文章目录 题目 论文总览 Part 1：论文导读 研究背景 研究成果 论文精读 摘要 论文小标题 VGGNet 网络结构 Classification Framework Training Testing Implementation Details Classification Experiments Single Scale Evaluation Multi-Scale Evaluation Multi-Crop Evaluation Convent Fusion Comparison With The State Of The Art 论文总结 题目： VggNet：《Very Deep Convolutional Networks for Large-Scale Image Recognition》，大规模图像识别的深度卷积网络。 论文总览 首先，读一篇论文，我们第一遍通常需要泛读，即读这篇论文的题目，摘要，各个部分的标题和小标题，以及图片和表格。 下面是泛读之后整理出该篇论文大致分成5个部分。 Part 1：论文导读研究背景 VGGNet 这篇论文的主要贡献就是在于从网络深度这一角度出发，对卷积神经网络进行了改进。非常详细的评估了网络深度所带来的影响，证明了网络的深度对于性能的提升具有举足轻重的作用。而且由于文中训练的两个16层和19层的网络由于其强大的泛化能力，在之后得到了非常广泛的应用。 VGGNet 主要特点： 网络很深 卷积层中使用的卷积核很小，且都是3*3的卷积核 研究成果 VGGNet 在2014年的 ImageNet Challenge 中获得了分类任务的第二名和定位任务的第一名。而且在分类任务中，只和获得冠军的 GoogLeNet 只相差了 0.1%，而且在单个网络中，VGG 是表现最好的，误差是 7.0%，比 GoogLeNet 的 7.9% 高了 0.9 个百分点。 Part 2：论文精读摘要下面，我们先来看看摘要。 我们可以将摘要总结如下： 这篇论文主要研究的是卷积神经网络深度对分类准确度的影响 我们整个网络都使用 3*3 的卷积核，成功将深度扩大了16-19层，并且得到了一个很好的效果 VGGNet 获得了2014年 ImageNet Challenge 的定位任务第一名和分类任务第二名 该模型的泛化能力很强，运用到其它数据集上也得到了很好的效果 表现最好的两个模型已经投入到未来的研究中 论文小标题 从小标题的个数可以看出，第4部分的子标题最多，我们应该重点关注，其次应该关注第2、3部分。 当我们正式进入某一部分时，我们可以先看一下，该部分有没有 Overall、Conclusion、Discussion等等。或许我们先从该部分入手，先了解到该部分的大体内容，再返回去看具体的实现细节。 那么我们先从网络的架构（Configurations）入手，从上面的小标题可以看出，我们可以先从 2.3 小节入手。 2. VGGNet 网络结构我们先看 2.3 的 discussion。 可以从上面一段文字总结如下： 整个神经网络都是使用的 3*3的卷积核 通过堆叠多个33的卷积核来代替大尺度卷积核，堆积2个33的卷积代替一个55的卷积，堆叠3个33的卷积代替一个7*7的卷积 这样做的好处：不仅能使决策函数更有区别，而且使得参数大大减少 可以从上面一段文字总结如下： 使用 1*1 的卷积可以在不影响卷积层的结果的情况下增加决策函数的非线性。 可以从上面一段文字总结如下： 这次比赛的冠军 GoogLeNet 也使用了非常深的网络（22层）和小的卷积核（11，33，5*5）。它们使用为了减少计算量，设计更为复杂，更积极地减少了第一层的特征图的空间分布。但是从单个网络的分类准确率来看，VGGNet 的表现要优于 GoogLeNet。 接下来，我们再来看 2.3 小节中的图。 在实验中，一共尝试了上面六种模型（每一列是一种模型），模型中都使用了是 3x3 的卷积核大小，在模型 C 中尝试了 1x1 的卷积核，模型的深度从左向右依次增加。为了简洁方便，表格中只展示了卷积操作和池化操作，没有显示激活函数（在每个卷积层和全连接层后都有激活函数）。而且我们发现每层的通道数很小，第一层的通道数只有64，之后每进行一次最大池化，通道数变为之前的2倍，直到增加到512为止。 下面是16层的 VGGNet 的模型图。 图中符号表示： conv3-64：卷积核的大小为 3*3，输出通道数为 64 conv1-256：卷积核大小为 1*1，输出通道数为 256 FC-4096：全连接层，输出神经元个数为 4096 FC-1000：全连接层，输出神经元个数为 1000 maxpool：采用最大池化 关于Table 2 的描述，在 2.2 小节中，我们来看看 2.2 小节。 Table 2 展示了上面六种模型中的参数个数，从 Table 1 中，我们知道模型的深度是从11层增加到了19层，尽管深度很深，但是网络的权重的数量是不大于一个更浅更宽的网络的。 最后我们在来看看整体网络的架构（2.1）。从上面几段话，可以总结如下： 每个模型的输入都是 224x224 大小的RGB图片，而且需要在训练集上进行正则化。 在卷积层中使用的是 3x3 的卷积核，在模型 C 中使用了 1x1 的卷积核 六个模型都有5个最大池化层，并且池化层中使用的都是 2x2 的卷积核，并且 stride 为 2 所有的隐藏层都有激活函数 LRN（局部响应正则化）不能改善性能，反而会导致增加内存消耗和时间消耗 3. Classification Framework 下面我们接着看第3节，该节主要描述的是网络中训练和评估的细节。我们先从 3.1 的 Training 开始。 3.1 Training 以上几段主要介绍了在训练过程中参数的设置以及初始化，以及扩充数据集的方法。总结如下： batch_size = 256 momentum = 0.9 L 2 L_2L2 正则项：5 ⋅ 1 0 − 4 5·10^{-4}5⋅10−4 dropout：p = 0.5 learning rate：0.01（当验证集准确度不变时，learning rate 变为原来的 1/10） 随机初始化权重，然后用模型 A 进行训练，然后将优化后得到的权重作为更深层的网络的前4层卷积层和最后3个全连接层的初始化权重，并且这些层的学习率不进行衰减。其余层进行进行随机初始化，权重初始化为均值为0，方差为0.01的正态分布，偏差为0。 但是他们在论文提交之后发现，可以不用上面的方法初始化权重，直接使用 Glorot &amp; Bengio(2010) 的随机初始化程序就能得到很好的效果。下面是 Glorot &amp; Bengio 的初始化方法。 他们使用随即裁剪的方式将输入的图片大小固定在 224x224。为了扩充数据集，采用随机水平翻转和随机RGB颜色扰动 下面是对于训练图片大小的设置。上面采取了两种方法来设置训练图片的大小 S。 第一种方法：固定 S，在实验中，评估模型用了两种图片大小：256 和 384。第一次训练固定图像大小 S = 256，为了加快 S = 384 的网络，将 S = 256 模型训练得到的参数作为 S = 384 模型的初始化权重，初始化学习率为 0.001 第二种方法：多尺度的训练。不固定训练图片的大小，将其固定在一个范围中 [256, 512]，在训练时，考虑到不同尺度的图片作为训练集训练网络对训练是有益的，也可以看做通过尺度抖动增加训练数据集。这样训练出来的模型可以识别各种大小的图片，由于速度方面的原因，我们训练多尺度模型的方法是对相同配置的单尺度模型的所有层进行微调，预先用固定的S = 384进行训练。 3.2 Testing下面让我们来看一下测试数据集。 总结如下： 用一张测试图片的不同大小进行测试，最后取这些结果的平均值作为该图片的结果，这样也会改善性能。 在最后一个卷积层的最后我们需要做一个最大/平均池化，为了使得能够和全连接层连接上，所以需要将最后一个卷积层的输出进行规定。 举个栗子：假设输入的图片大小为 224x224x3，那么最后一个卷积层的输出为 7x7x512。那么如果输入图片大小为 448x448x3，那么最后一个卷积层的输出为 14x14x512。这样两个不同的尺度就不能连接同一个全连接层，所以需要对最后一个卷积层的输出做一个规定大小。那么只需要对他们做一个均值（最大）池化操作，7x7x512 池化之后就是 512，14x14x512 池化之后也是 512，这样就能与全连接层相连接了。 通过水平翻转图像增加扩充测试数据集，最后将原始图片和翻转后的图片的结果平均值作为该图片的最终结果。 我们在评估网络时，把每张图片变为3个尺寸，从每个尺寸的图片中随即裁剪出50个不同的图片，然后一张图片就变成了150张图片 3.3 Implementation Details最后我们再来看看实现细节（3.3） 总结： 网络进行训练和评价以及训练和评估全尺寸多尺度图像都是使用一个系统上的多个 GPU 。多 GPU 训练利用数据并行性，将每批训练图像分割成若干 GPU 批次，在每个GPU上并行处理。计算完 GPU 批处理梯度后，取其平均值，得到整个批处理的梯度。梯度计算是同步的跨 GPU，因此结果和单一 GPU 训练是完全相同的。 网络在4个 NVIDIA Titan Black GPUs 训练单个网络花费了 2-3 周。 4. Classification Experiments 在第4节中，主要呈现了在 ILSVRC-2012 数据集上的分类结果，分类表现主要有两种评价指标：top-1 and top-5 errro，top-5 error 是 ILSVRC 的主要评价指标。 4.1 Single Scale Evaluation 单尺度评估。首先我们来看看4.1小节给出的表格。 对于模型 A，A-LRN，B，它们都采用的是固定 S = 256，并且我们发现模型 A-LRN 的表现还没有模型 A 好，所以对于后面的模型，都没有使用 LRN（局部响应正则化），但是我们观察到从模型 A 到模型 B，随着深度的增加，top-1 和 top-5 error 也在下降。 再来观察模型 C、D、E，它们的 train 都测试了3种图片尺度，分别是 S=256，S=384，S=[256;512]。我们只看三个模型的 S=256 和 S=384，我们很容易发现不管哪一种模型，当 S=384，其模型的 top-1 和 top-5 是要优于 S=256 的。那是因为图片的分辨率越高，我们能够更容易捕捉到一些空间特征，所以其分类准确度就越高。 最后，我们再来看看的三种模型的 S=[256;512] 的这种情况，我们很容易发现这种情况的分类结果不管在哪一种模型中都是表现最好的。这也证明了通过尺度来扩充训练集确实有助于捕获多尺度图像统计。 4.2 Multi-Scale Evaluation 多尺度评估。主要评估在测试阶段尺度抖动对分类准确度影响。当用固定图片大小S进行训练得到的模型，会用一张测试图片的三种尺寸大小进行评估，那么三种图片大小分别为：S-32，S，S+32。当训练时不是使用的固定 S 进行训练，S 是一个变量，属于 [S m i n S_{min}Smi**n, S m a x S_{max}Sma**x]，那么我们在评估时，测试图片的大小分别是：S m i n S_{min}Smi**n, 0.5 ( S m i n + S m a x ) 0.5(S_{min} + S_{max})0.5(Smi**n+Sma**x), S m a x S_{max}Sma**x。 评估结果如下： 根据表格我们可以得出结论：在测试阶段的尺度抖动相较于单尺度的相同模型会有更好的表现。其中模型 D 和 E 表现最好。表现最好的单个网络在验证数据集上 top-1 和 top-5 error 达到了 24.8%/7.5%，在测试数据集上，模型 E 达到了 7.3 % 的 top-5 error。 4.3 Multi-Crop Evaluation 多裁剪评估。这里主要用到两种评估方法，一种是 dense，即评估时所使用的图片是整张图片，不经过任何裁剪。那么另一种就是 multi-crop，就是评估时使用的是裁剪后的图片。评估结果如下表： 从评估结果来看，使用 multi-crop 要比使用 dense 的表现稍微好一些，而且两种方法结合使用的表现比单独使用任何一种方法的效果都要好，因为两种方法是互补的。 4.4 Convent Fusion 模型融合。通过融合几种模型，最后取各个模型的 soft-max 结果的平均值作为模型的输出。下面是融合不同模型得到的实验结果。 可以从实验结果发现，融合一个模型 D 和模型 E ，并且在评估时使用 multi-crop 和 dense 的方法得到的表现最好。 4.5 Comparison With The State Of The Art 主要是和 ILSVRC 比赛中表现比较好的模型进行比较，下表是在挑战赛中表现比较好的模型。 在 2014 年的挑战赛中，GoogLeNet 以 6.7% 的 error 夺冠，VGGNet 以 6.8% 的 error 获得第二名。但是如果从一个网络的分类准确度来看，VGG 是以 7.0% 的 error 要优于 GoogLeNet 的 7.9%。 论文总结 在研究完每篇论文之后，我们都需要做一个总结。 那么我们先来看一下这篇论文的总结是什么?再次强调了深度确实能够增加分类准确度。 下面就来进行自我总结。 创新点 整个网络都采用 3x3 的卷积核，从而增加神经网络的深度。两个3x3卷积核的堆叠代替一个5x5卷积核，三个3x3卷积核代替一个7x7卷积核。这样一方面能够减少参数的数量，另一方面拥有更多的非线性变化。 在卷积结构中引入1x1的卷积核，在不影响输入输出维度的情况下，引入非线性变换，增加网络的表达能力，降低计算量 通过预训练的方式来更好的初始化权重，加快训练的收敛速度 采用 Multi-Scale 的方式训练和预测，可以扩充数据集，防止过拟合，提升预测准确率。 深层网络更适合于大的数据集 启发点 深度能够提高网络的分类准确率 为了加快收敛速度，可以使用预训练的方式初始化权重 在更深层的网络中，LRN方法并没有什么用，反而会导致内存和时间的消耗 通过堆叠小卷积核可以减少网络参数，增加网络深度，提升网络性能 在训练和测试使用 Multi-Scale 可以扩充数据集，防止过拟合","link":"/posts/483895fb/"}],"tags":[{"name":"个人博客","slug":"个人博客","link":"/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"说明","slug":"说明","link":"/tags/%E8%AF%B4%E6%98%8E/"},{"name":"AlexNet","slug":"AlexNet","link":"/tags/AlexNet/"},{"name":"论文","slug":"论文","link":"/tags/%E8%AE%BA%E6%96%87/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"神经网络","slug":"神经网络","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"categories":[{"name":"关于","slug":"关于","link":"/categories/%E5%85%B3%E4%BA%8E/"},{"name":"计算机","slug":"计算机","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"人工智能","slug":"计算机/人工智能","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]}